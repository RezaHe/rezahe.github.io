import "./projectBodies.css";
import Zoom from 'react-medium-image-zoom'
import 'react-medium-image-zoom/dist/styles.css'

const ProjectBody01 = () => {
    return (
        <div>
            <em style={{fontSize: "15px"}}>Last updated: 17 Nov, 2023</em>
            <div style={{margin: "0 auto", textAlign: "center", padding: "20px"}}>
                <figure>
                    <Zoom>
                        <img
                            alt="SpartanX Logo"
                            src="../projects_spartan_x_01.jpg"
                            width="200"
                        />
                    </Zoom>
                    <figcaption style={{fontSize: "15px", paddingLeft: "20px", paddingRight: "20px"}}><em>
                        SpartanX
                    </em></figcaption>
                </figure>
            </div>

            “Is it possible?” This was the first question every person asked me when I explained what we do in our
            startup. At times, I felt hopeless about the results of our work. However, the primary reason we persevered
            in our struggle was the realization that major companies, such as <a target="_blank" rel="noreferrer"
                                                                                 href="https://www.rentec.com/Home.action?index=true">RenTech</a> hedge
            fund and <a target="_blank" rel="noreferrer"
                        href="https://www.blackrock.com/corporate">BlackRock</a> investment management, have
            successfully employed similar approaches, serving as examples of success.
            <br/><br/>
            In Cardano Trader, our goal was to create a fully automated system for managing assets in the Tehran Market
            using AI, particularly ML and DL methods. I dedicated two and a half years to this endeavor, collaborating
            with two friends who joined me later. We worked day and night on this project. Now, with two years having
            passed since the failure of our startup and the expiration of our NDA, I aim to share some insights about
            our journey, highlighting both the challenges and successes we experienced in implementing this idea in the
            real world.
            <br/><br/>
            The system comprises three main components: data listener, an AI core, and an accounts manager.
            The data listener component functioned as a scraper, collecting technical data primarily from two
            sources—the market's official page and the broker's page. This part's responsibility was to publish data in
            memory, and to minimize delays, the data was directly written to <a target="_blank" rel="noreferrer"
                                                                                href="https://www.softprayog.in/programming/interprocess-communication-using-system-v-shared-memory-in-linux#:~:text=Shared%20memory%20is%20one%20of,the%20message%20queues%20and%20semaphores.">shared
            memory</a>. The
            AI core served as the hub for various algorithms employing different strategies. These
            algorithms determined, at each time frame, the selection of symbols (where we could invest our money in
            different symbols in the market) and the portion of the entire asset to be allocated. We implemented three
            various algorithms for this segment, with SpartanX, representing a fine-tuned version of
            Spartan, being one of them. Lastly, the accounts manager, also a scraper, managed orders generated by each
            algorithm in the AI core,
            facilitating their submission, modification, or cancellation on the exchange page for multiple accounts.
            <br/><br/>
            In this article, I aim to elucidate SpartanX and the concept behind it. I won’t delve into the other
            components and algorithms, as they warrant separate articles. Initially, I will delve into the origin of
            the SpartanX idea by presenting results from its precursor concepts. Then, I will provide a detailed
            explanation. Finally, I will present real-world test results and conclude the article by addressing
            practical issues.
            <br/><br/>
            <div className="heading-1">Before Going Deeper</div>
            <br/><br/>
            It is worthwhile to mention that in real-world applications, there are many things you need to do beyond
            just loading data and training a model. Consider the following aspects to be addressed in a full data
            science project: gathering and cleaning data, reconstructing missing data, hardware requirements,
            versioning and checkpointing the models, visualization, and validation, real-time monitoring, testing, and
            retraining based on test results.
            <br/><br/>
            <div className="heading-1">About Tehran Market</div>
            <br/><br/>
            The Tehran Stock Exchange is Iran’s largest stock market, with an estimated daily transaction value of about
            $120 million. At the time we developed our system, there were approximately 750 active companies, and their
            shares could be traded as symbols.
            <br/><br/>
            The market has some restrictions and rules that pose challenges for a data scientist. For example, the
            market opens at 9 AM and closes at 12:30 PM, although the opening hours have occasionally changed.
            Additionally, each day, each symbol must fluctuate within a pre-determined range based on yesterday's
            closing price. This range varies for different symbols. Moreover, trading for each symbol must halt due to
            regulatory requirements, leading to the blocking of all assets. Designing a system must take these scenarios
            into consideration.
            <br/><br/>
            <div style={{margin: "0 auto", textAlign: "center", padding: "20px"}}>
                <figure>
                    <Zoom>
                        <img
                            alt="SpartanX Logo"
                            src="../projects_spartan_x_02.jpg"
                            width="100%"
                        />
                    </Zoom>
                    <figcaption style={{fontSize: "15px", paddingLeft: "20px", paddingRight: "20px"}}><em>
                        The price of the symbol DELOR in Rials (the currency of Iran) is depicted from mid-April to
                        mid-October 2020. The price is represented by dots for different days, with colors indicating
                        positive/negative trends—red, white, or green. White rectangles indicate the price limits for
                        each day. The red and grey vertical areas represent days when the symbol's trade is restricted.
                    </em></figcaption>
                </figure>
            </div>
            <br/><br/>
            <div className="heading-1">Start: Prediction of the Future of Each Symbol</div>
            <br/><br/>
            The initial idea involves predicting the future price of each symbol and subsequently selecting the best
            symbols based on both their anticipated future and the confidence level of these predictions. For instance,
            if we estimate that symbol X's price will increase by 5% in 7 days with a confidence level of 70%, and
            symbol Y's price will rise by 3.5% in 7 days with a confidence level of 80%, we can allocate our assets
            among these two symbols according to our risk threshold. Another consideration is reserving a portion of our
            assets for potential future opportunities, a decision that is intricate and will be discussed later.
            <br/><br/>
            At the start of our startup, we trained various regression models and networks to predict the future price
            of each symbol. However, we encountered several challenges:
            <br/>
            <ul>
                <li>
                    Determining the prediction horizon: How many future points should be considered—next minute, next
                    hour, next day, next week, or next month?
                </li>
                <li>
                    Measuring prediction confidence: How can we quantify the confidence of our predictions?
                </li>
                <li>
                    Feature selection: What data should be included as features? Should additional economic measures
                    like MACD, EMA, and RSI be used?
                </li>
                <li>
                    Model training: Should a single model be trained for all symbols, or is it more effective to use
                    separate models for different symbols?
                </li>
                <li>
                    Non-stationary price history: The price history is non-stationary and varies over time and among
                    symbols. How can we address this variability?
                </li>
            </ul>
            <br/>
            Initially, we aggregated all symbols throughout their entire history to create a comprehensive dataset.
            Various features, such as MACD, were computed for each price and incorporated into our dataset. To address
            the non-stationary problem, we implemented a moving window of a specified size and utilized the min-max
            normalization method to maintain the price range within a specific interval. As for the model's response, we
            calculated the relative price change, representing the change in future price relative to the current price.
            <br/><br/>
            Despite the involvement of all symbols and a dataset size of approximately 200,000 samples, the abundance of
            features posed the curse of dimensionality problem for the model. To address this, we initially employed a
            Random Forest model to identify the most informative features, ultimately narrowing them down to about 20
            key features.
            <br/><br/>
            Over more than two months, we trained various models to predict future prices, but the results were
            consistently discouraging: almost always yielding predictions of zero. Regardless of changing both the model
            architecture and the dataset, the predictions remained stuck at zero. We explored a range of models,
            including RNN, LSTM, GRU, 1-dimensional CNN, Gaussian Process regression, and even Transformer.
            Additionally, we experimented with different selections of economic measures as features, various
            normalization methods, diverse time horizons from hours to weeks, and varied selections of data related to
            different dates in the market.
            <br/><br/>
            <div className="heading-1">What is the Meaning of Zero?</div>
            <br/><br/>
            We arrived at two possible explanations for our results. First, it might be a flawed assumption to aggregate
            all market data together. It is plausible that symbols' prices vary in distinct ways. For instance, Symbol
            X's price could rise under one specific condition, while under the same condition, the price of Y might
            drop. Moreover, this rule for a single symbol can change over time. The same condition that contributed to
            the rise in the price of Symbol Z two years ago may not have the same effect this year due to the overall
            market being in a harsh condition.
            <br/><br/>
            Secondly, we considered that the cause of price change within the time frame we examined might not be
            adequately represented in our features. For instance, if we aim to predict the price of Symbol Z in the next
            month, relying on daily trade value, current price, RSI, and similar features might be insufficient.
            Instead, the most significant determinant could be found in the net sales of the company. Unfortunately,
            thess types of fundamental data are not present in our dataset, and we do not have access to them.
            <br/><br/>
            <div className="heading-1">SpartanX</div>
            <br/><br/>
            So, we decided to shift our perspective and implemented three major changes. The first change involved
            time-dependent clustering of symbols. Our assumption was that the price dynamics of each symbol vary
            smoothly over time (with time referring to the day in this context). On any given day, all 750 symbols are
            grouped into 10 different clusters based on certain features extracted from their price fluctuations.
            <br/><br/>
            The second change involved approaching the problem as a classification problem rather than a regression one.
            In fact, accurately predicting the exact future price is challenging. When consulting an expert about
            a symbol, they often provide general directional insights, such as "It will go up" or "It will drop." In
            practice, the focus is more on understanding the overall trend rather than pinpointing the exact price.
            <br/><br/>
            Indeed, we labeled our data at each point as either a positive or negative sample. The label signifies that
            buying
            the share at that time point could result in a benefit. However, a challenge arises: At which point sell
            that share? How much benefit do you want to make and sell your share? Do you want to hold the share if the
            price drops, perhaps for a return? The classification of good/bad labels is highly dependent on the chosen
            trading strategy.
            <br/><br/>
            The third change involved reducing the prediction horizon to one hour. After thorough examination, I can
            confidently state that there is no substantial information in the technical data of the market for
            predicting the long-term future of a symbol, such as a month later. The market, being influenced by
            significant players, involves human decision-making based on several unpredictable factors. However, in a
            short time period, we observed that the price exhibits a discernible dynamic.
            <br/><br/>
            This entails a trade-off between profit and prediction ability. Lowering the future horizon allows for
            better price prediction, but short-term profits are typically modest. This is where the concept of
            High-Frequency Trading comes into play. In this method, numerous small trades are executed, and the
            cumulative result of these trades amounts to a significant profit.
            <br/><br/>
            Hence, SpartanX is divided into two interconnected sub-systems: the Signal Generator and the Stream Manager.
            The Signal Generator generates, every 2.5 seconds, a vector of probabilities for all symbols. Each entry in
            the vector represents the goodness of buying that symbol at that specific time (not predicting the future
            price
            value). The Stream Manager is responsible for managing the entire asset and utilizing it to invest in
            various symbols.
            <br/><br/>
            <div className="heading-1">Signal Generator</div>
            <br/><br/>
            At the beginning of each day, the Signal Generator extracts 5 features representing the price fluctuations
            of each symbol over the last 30 days. This results in a 5x30 matrix for each symbol. Then, we
            utilized <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/1802.03426">UMAP</a> to
            reduce these 150 features to 2 dimensions. Subsequently, we used <a target="_blank" rel="noreferrer"
                                                                                href="https://link.springer.com/chapter/10.1007/978-3-642-37456-2_14">HDBScan</a> to
            categorize all 750 symbols into 10 clusters based on their reduced 2 features. This process is repeated
            daily, assigning each symbol to one of the 10 clusters. It is worth noting that a symbol may be in a
            different cluster today than it was 20 days ago. To account for variations in UMAP reduction and HDBScan
            clustering, we employed <a target="_blank" rel="noreferrer"
                                       href="https://en.wikipedia.org/wiki/Procrustes_transformation">Procrustes</a> to
            align these features for consecutive days.
            <br/><br/>
            <div style={{margin: "0 auto", textAlign: "center", padding: "20px"}}>
                <figure>
                    <Zoom>
                        <img
                            alt="Symbols Clustered"
                            src="../projects_spartan_x_03.gif"
                            width="100%"
                        />
                    </Zoom>
                    <figcaption style={{fontSize: "15px", paddingLeft: "20px", paddingRight: "20px"}}><em>
                        Symbols clustered
                    </em></figcaption>
                </figure>
            </div>
            <br/><br/>
            We found the 10 clusters to be intriguing as they exhibited a high sensitivity to related symbols. For
            instance, the symbol Khodro consistently appeared as the closest symbol to Vsapa on most days. This
            alignment is meaningful as both companies are prominent automobile manufacturers and share significant
            similarities. It is noteworthy that we didn't explicitly feed this knowledge to our model; rather, it emerged
            based on price variability, effectively identifying and recovering related symbols.
            <br/><br/>
            Examining the price of sample symbols across various clusters revealed a compelling pattern. In essence, our
            approach enabled us to segregate symbols based on their liquidity. Less liquid symbols exhibited more
            significant price jumps, while more liquid symbols proved resistant to large price changes due to the
            substantial support from high volumes of buy and sell orders. This separation not only provided valuable
            insights into market dynamics but also paved the way for tailored trading strategies, recognizing that
            trading in different symbols necessitates distinct approaches contingent on the liquidity of each symbol.
            <br/><br/>
            [insert image]
            <br/><br/>
            Then, we trained different models for these clusters, recognizing that the price dynamics differ
            among them. The model's output, as discussed earlier, signifies the desirability of buying. A higher
            probability suggests a potentially larger profit when buying shares of that symbol at that time. For
            labeling data, we established a simple trading strategy: we buy a share at time 't' with price 'p.' If any
            of the following criteria are met, we sell that share:
            <br/>
            <ol>
                <li>
                    If the current price falls by less than 2% of the maximum price in the time window from time 't' to
                    the present.
                </li>
                <li>
                    If the price falls by less than 1% of 'p.'
                </li>
                <li>
                    If the current time surpasses 1 hour from time 't.'
                </li>
            </ol>

            <br/>
            We iterated through all time points (sampled with a 2.5-second period) in the dataset for each day and apply
            these criteria. If the sell price is higher than the buy price plus the exchange fee, that time point is
            labeled as 'good.' Conversely, the remaining points are labeled as 'bad.'
            <br/><br/>
            By training our model in this manner, we ensured that if the model accuracy is high, and we follow these
            predictions along with the aforementioned trading strategy, we can benefit from the market.
            <br/><br/>
            We utilized a <a target="_blank" rel="noreferrer"
                             href="https://arxiv.org/abs/1706.03762">Transformer</a> network
            for this purpose due to its foundation on the attention mechanism. Unlike
            RNN, which struggles with inferring patterns occurring at different time scales, the Transformer, leveraging
            Multi-Head Attention blocks, effectively addresses this limitation. To tailor the Transformer for our
            problem, we made specific adjustments to the architecture, such as removing embedding and modifying
            positional encoding.
            <br/><br/>
            [insert image]
            <br/><br/>
            <div className="heading-1">Stream Manager</div>
            <br/><br/>
            In an imaginary scenario where we have access to a perfect model that predicts the future of each symbol
            with high confidence, say 90%, determining the best approach for investment becomes nuanced. While one might
            suggest investing all assets in the share of a symbol the first time, there is a 10% chance it could be a
            bad
            decision leading to losses. Alternatively, waiting for a better opportunity to buy another symbol and
            potentially gain greater benefits is also a consideration. Adding to the complexity, if we already hold
            shares of symbol X and it is currently in a loss, the decision of whether to sell those shares to free up
            assets for a symbol with a higher probability introduces another layer of complexity to the investment
            strategy.
            <br/><br/>
            In my opinion and based on my experience, the selection of these strategies holds more significance than
            predicting the future price. This aspect is closely tied to economic topics such as risk management and
            asset management.
            <br/><br/>
            We devised a simple yet effective strategy for this. Initially, our entire asset, let's say 1, is divided
            into a specified number of parts, denoted as 'streams,' let's say N. In each trade, we utilize one of these
            streams to buy and sell shares. At each time point, the system examines all available streams. If one of
            them is available, the Stream Manager consults the Signal Generator for promising symbols to buy. If the
            probability of a symbol exceeds a threshold and that symbol has not been purchased before, the stream is
            allocated to that symbol. The Stream Manager continuously monitors all active streams, and, as previously
            outlined, if any of these criteria are met, the shares of that symbol are sold:
            <br/>
            <ol>
                <li>
                    If the current price falls by less than 2% of the maximum price in the time window from time 't' to
                    the present.
                </li>
                <li>
                    If the price falls by less than 1% of 'p.'
                </li>
                <li>
                    If the current time surpasses 1 hour from time 't.'
                </li>
            </ol>

            <br/>
            The parameters of this method play a crucial role in determining the overall benefit. For example, if the
            number N is increased, the profit will decrease since the total profit is divided by N; simultaneously, the
            risk will decline. Therefore, finding the optimal set of parameters is highly impactful and poses a
            challenging problem. We identified the best set through grid searching across all possible combinations over
            a 3-week period, using five powerful machines with a Core i9 CPU. The following image illustrates the
            impact of changing some of these parameters on the overall profit.
            <br/><br/>
            [insert image]
            <br/><br/>
            Recall the labeling mechanism in the Signal Generator part. It is important to note that labels are
            dependent
            on this parameter set. The best parameter set and the profit are also influenced by the output of the Signal
            Generator. Yet, we should fine-tune these two sub-systems together. Fine-tuning these two sub-systems
            together is a non-trivial task, and currently, we fine-tune Transformer models after identifying the best
            set.
            <br/><br/>
            <div className="heading-1">Results and Discussion</div>
            <br/><br/>
            The entire structure underwent multiple tests. In a test spanning approximately one and a half months with
            an initial asset of $100,000, we achieved a 15% gain. Notably, in one day, two streams were bought and sold
            in a symbol within just 6 seconds. However, upon further analysis, we discovered that this profit is heavily
            influenced by market circumstances. High-frequency trading necessitates high liquidity as orders must be
            executed swiftly. Additionally, this strategy performs well in neutral markets, exhibiting effectiveness
            neither in a bullish nor a bearish trend.
            <br/><br/>
            This strategy encountered two practical issues during real tests, resulting in a decline in overall
            performance. Firstly, buy orders often failed to complete, primarily due to liquidity issues. Secondly, as
            mentioned earlier, the Tehran exchange market's rule stipulates a specific price range. Consequently, during
            a downward trend, shareholders seek to sell their shares, leading to a lack of buyers and causing a price
            saturation with a lower bound. This, in turn, results in some streams being blocked for several days,
            preventing their use in other symbols for profit generation. These challenges significantly impacted the
            algorithm's performance.
            <br/><br/>
            As suggested earlier, the most crucial factor in this type of work is not finding the best machine to
            predict the future price; rather, it is more important to implement strategies and methods for
            decision-making based on the current situation. Reinforcement learning may offer a promising avenue. By
            defining agents capable of taking actions like creating and canceling orders, and modeling rewards as the
            profit from trading within a specific time period based on probabilities generated by the Signal Generator,
            a more adaptive approach could be achieved. Although we attempted to pursue this direction, time constraints
            hindered us from completing the task, ultimately leading to the collapse of our startup.
        </div>
    );
};

const ProjectBodies = [ProjectBody01, ProjectBody01, ProjectBody01];
export default ProjectBodies;
